# -Human-Activity-Recognizer-project
A real-time Human Activity Recognizer built using TensorFlow.js and PoseNet. Detects poses from webcam video and classifies various activities like sitting, jumping, farming, and more using keypoint-based logic. Runs directly in the browser with no backend required.



# Human Activity Recognizer (with PoseNet and TensorFlow.js)

This project is a browser-based Human Activity Recognizer that uses the PoseNet model from TensorFlow.js to detect and classify human activities based on live webcam footage. The recognizer identifies various physical activities and maps them to domains such as agriculture, industry, services, education, healthcare, recreation, and more.

## ğŸš€ Features

- Uses webcam to detect real-time human poses
- Classifies activities like:
  - Sitting, Standing, Jumping, Raising Hands, etc.
  - Domain-based activities like Farming, Teaching, Sports, Worship, etc.
- Draws keypoints over the live video feed
- Built using HTML, CSS, and JavaScript
- Uses TensorFlow.js and PoseNet model

## ğŸ“¸ Demo

![App Screenshot](screenshot.png)

> You can add a screenshot by taking one and saving it as `screenshot.png` in your project folder.

## ğŸ› ï¸ Tech Stack

- HTML5
- CSS3
- JavaScript
- TensorFlow.js
- PoseNet (Pretrained model)

## ğŸ”§ How to Run Locally

1. Clone the repository:
   ```bash
   git clone https://github.com/<your-username>/human-activity-recognizer.git
   cd human-activity-recognizer
